{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SLURM\n",
    "- Simple Linux Utility for Resource Management \n",
    "[SLURM website](https://slurm.schedmd.com/)\n",
    "- Development started in 2002 at Lawrence Livermore National Laboratory\n",
    "- Overview:\n",
    "    * open source\n",
    "    * fault-tolerant\n",
    "    * highly scalable cluster management and job scheduling system\n",
    "\n",
    "\n",
    "- Main functions \n",
    "    * allocates exclusive and/or non-exclusive access to resources (compute nodes) to users for some duration of time so they can perform work\n",
    "    * provides a framework for starting, executing, and monitoring work (normally a parallel job) on the set of allocated nodes\n",
    "    * arbitrates contention for resources by managing a queue of pending work\n",
    "\n",
    "- Configuration specific to an HPC center; CARC has its own setup\n",
    "\n",
    "# Some terms\n",
    "\n",
    "- Head Node – The system that controls the cluster\n",
    "- Worker (Compute) Node – Systems that perform the computations in a cluster\n",
    "- Login Node – System that users log into to use a cluster\n",
    "- Scheduler – Software that controls when jobs are run and the node they are run on\n",
    "- Shell – A program that users employ to type commands\n",
    "- Script – A file that contains a series of commands that are executed\n",
    "- Job – A chunk of work that has been submitted to the cluster\n",
    "\n",
    "# How does it work?\n",
    "\n",
    "## A simple explanation:\n",
    "![SLURM simple](../images/slurm-simple.png)\n",
    "\n",
    "## A not-so-simple explanation\n",
    "![SLURM not-simple](../images/slurm-not-simple.png)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A quick prep:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env PATH=/spack/utilities:/usr/local/bin:$PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Commonly used slurm commands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. `sinfo` – reports state of the partitions and nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sinfo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1a. `sinfo2` - an alias that is easier to remember than `sinfo -o \"%60N %10P %8t %8D %10X %10Y %10m %25G %b \"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sinfo2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Codes for node status\n",
    "- ALLOCATED – the node has been allocated to one or more jobs\n",
    "- DOWN – the node is unavailable for use\n",
    "- DRAINING – the node is currently executing a job, but will not be allocated additional jobs\n",
    "- IDLE – the node is available for use\n",
    "- MAINT – the node is currently in a reservation with a flag value of “maintenance”\n",
    "- MIXED – the node has some of its CPUs ALLOCATED while others are IDLE\n",
    "- RESERVED – the node is in advanced reservation and not generally available"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What partition should I use\n",
    "- debug – small, short or test jobs; short queue\n",
    "- main (default) – most jobs (serial and small-to-medium), can utilize older K40 gpus\n",
    "- epyc-64 – medium-to-large parallel jobs\n",
    "- gpu – jobs that require GPUs (P100, V100, A100, A40)\n",
    "- largemem – jobs requiring lots of memory (up to 1TB)\n",
    "- oneweek – long-running jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Limits\n",
    "|Partition (queue) |Maximum runtime   | Maximum concurrent CPUs  | Maximum concurrent GPUs  | Maximum concurrent memory  | Maximum concurrent jobs running  | Maximum concurrent jobs queued  |\n",
    "|---|---|---|---|---|---|---|\n",
    "|main   | 48 hours  | 1200  | 36  | ---  | 500  | 5000  |\n",
    "|epyc-64   | 48 hours  | 1200  | N/A  | ---  | 500  | 5000  |\n",
    "|gpu   | 48 hours  | 400  | 36  | ---  | 500  | 100  |\n",
    "|oneweek   | 168 hours  | 208  | N/A  | ---  | 500  | 50  |\n",
    "|largemem   | 168 hours  | 120  | N/A  | ---  | 500  | 10  |\n",
    "|debug   | 1 hour  | 48  | 4  | ---  | 5  | 5  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. `squeue` – reports state of jobs or job steps\n",
    "#### Job status can be:\n",
    "- PD PENDING – Job is awaiting resource allocation\n",
    "- R RUNNING – Job currently has an allocation\n",
    "- CD COMPLETED – Job has terminated on all nodes with an exit code of zero\n",
    "- CG COMPLETING – Job is in the process of completing. Some processes on some nodes may still be active\n",
    "- CA CANCELLED – Job was explicitly cancelled by the user or system administrator. The job may or may not have been initiated\n",
    "#### Common Pending status reasons:\n",
    "- Resources – Job is waiting for resources to become available\n",
    "- Priority – One or more higher priority jobs exist for this partition or advanced reservation\n",
    "- ReqNodeNotAvail – Some node specifically required by the job is not currently available\n",
    "- QOSMaxCpuPerUserLimit – The job has reached the maximum CPU per user limit\n",
    "- QOSMaxGresPerUser – The job has reached the maximum GPU per user limit\n",
    "- AssocGrpCPUMinutesLimit – The project account has run out of CPU time\n",
    "- InvalidAccount – the job’s account is invalid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2a. most commonly used - to check your jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!squeue --me"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2b. a popular use - to check jobs of a user (might be you)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!squeue -u ttrojan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2c. not commonly used - to see all jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!squeue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. `salloc` – allocates resources for a job in real time (we cannot test it here but we will in the terminal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`salloc`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. `sbatch` – submits a job script to queue for a later execution\n",
    "- Use module purge to clear automatically loaded modules\n",
    "- Pack short-running jobs together as job steps\n",
    "- By default, output log files are named `slurm-<jobid>.out` and saved to the submit directory with both standard output and standard error messages\n",
    "- Use `--output` and/or `--error` options to customize them\n",
    "- Formatting options can be used (e.g., `%x` = job name -> `%x.out`)\n",
    "\n",
    "| Option  | Default value  | Description  |\n",
    "|---|---|---|\n",
    "| --nodes=<number>  | 1  | Number of nodes to use  |\n",
    "| --ntasks=<number>  | 1  | Number of processes to use  |\n",
    "| --cpus-per-taks=<number>  | 1  | Number of cores per task  |\n",
    "| --mem=<number>  | 2GB  | Total memory (single node)  |\n",
    "| --mem-per-cpu=<number>  | 2GB  | Memory per processor core  |\n",
    "| --constraint=<attribute>  |   | Node property to request (e.g., xeon-2640v4)  |\n",
    "| --partition=<partition_name>  | main  | Request nodes on specified partition  |\n",
    "| --time=<D-HH:MM:SS>  | 1:00:00  | Maximum run time  |\n",
    "| --account=<account_id>  | Default project account  | Account to charge resources to  |\n",
    "| --mail-type=<value>  |   | Email notifications type; can be: begin, end, fail, all  |\n",
    "| --mail-user=<address>  |   | Email address  |\n",
    "| --output=<filename>  |   | File for standard output redirection  |\n",
    "| --error=<filename>  |   | File for standard error redirection  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's create and run a sample job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prepare directories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p ../../jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prepare a sample job script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_job=\"\"\"\n",
    "#!/bin/bash\n",
    "#SBATCH --nodes 1\n",
    "#SBATCH --ntasks 1\n",
    "#SBATCH --partition debug\n",
    "#SBATCH --time=00:05:00\n",
    "#SBATCH --chdir /home1/ttrojan/running-jobs-on-CARC-systems\n",
    "#SBATCH --account=<account_id>\n",
    "module purge\n",
    "module load usc\n",
    "echo \"Example start\"\n",
    "echo `date`\n",
    "sleep 180\n",
    "echo \"Example end\"\n",
    "\"\"\"\n",
    "with open('../../jobs/sample_job.sh', 'w') as fp:\n",
    "    fp.write(sample_job)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's check the file content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat ../../jobs/sample_job.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### It is time to submit the job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!sbatch ../../jobs/sample_job.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "#### Job status:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!squeue --me"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "#### SLURM variables\n",
    "| Variable  | Description  |\n",
    "|---|---|\n",
    "| SLURM_JOB_ID  | The ID of the job allocation  |\n",
    "| SLURM_JOB_NODELIST  | List of nodfes allocated to the job  |\n",
    "| SLURM_JOB_NUM_NODES  | Total number of nodes in the job’s resource allocation  |\n",
    "| SLURM_NTASKS  | Number of tasks requested  |\n",
    "| SLURM_CPUS_PER_TASK  | Number of CPUs requested per task  |\n",
    "| SLURM_SUBMIT_DIR  | The directory from which sbatch was invoked  |\n",
    "| SLURM_ARRAY_TASK_ID  | Job array ID (index) number  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. `srun` – submits a job for execution or initiate job steps in real time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`srun --mpi=pmix_v2 -n $NTASKS my_command`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. `scancel` – is used to cancel a job or job step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!scancel JOBID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. `sprio` – displays a detailed view of the components affecting job’s priority\n",
    "- Display job priority information\n",
    "- Can be difficult to interpret\n",
    "- After normalizing, a priority value closer to 1 means a higher priority"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sprio -j JOBID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. `sstat` – is sed to get information about the resources utilized by a job or job step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " !sstat -j JOBID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. `sacct` – is used to report job accounting information about active or completed jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sacct -j JOBID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Job exit codes:\n",
    "- Exit status, 0-255\n",
    "- 0 -> success, completed\n",
    "- Non-zero -> failure\n",
    "- Codes 1-127 indicate error in job\n",
    "- Exit codes 129-255 indicate jobs terminated by Unix signals\n",
    "\n",
    "More help: `man signal`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. `seff` – is used to display job efficiency for past jobs\n",
    "- Display job efficiency information for past jobs (CPU and memory use)\n",
    "- Is used  to optimize resource  requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!seff JOBID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. `scontrol` – is used to display or modify slurm configuration and state\n",
    "- Display or modify slurm configuration and state\n",
    "- Mostly for admins, some commands for users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!scontrol show partition main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!scontrol show node e23-02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!scontrol show job JOBID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. `jobinfo` - a useful wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!jobinfo JOBID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13. What's Next?\n",
    "\n",
    "To continue exploring jobs on CARC, and specifically learn how to create and  submit array jobs, please open the notebook in `02-Arrays/`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
